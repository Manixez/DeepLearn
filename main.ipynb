{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7e2058",
   "metadata": {},
   "source": [
    "# Klasifikasi Makanan Indonesia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1130d889",
   "metadata": {},
   "source": [
    "## Import & dependensi\n",
    "Bagian ini mengimpor semua library dan modul yang dipakai sepanjang skrip: PyTorch (core, nn, optim, DataLoader), numpy, metrik dari sklearn, utilitas time dan os, serta arsitektur pretrained MNASNet0.5 dari torchvision. Juga mengimpor modul kustom MakananIndo (dataset) dan check_set_gpu() (utility untuk memilih device GPU/CPU). Ini menyiapkan building block untuk load data, membangun model, training, dan evaluasi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7df577",
   "metadata": {},
   "source": [
    "## Pembuatan encoder label (create_label_encoder)\n",
    "Fungsi ini mengiterasi seluruh dataset (for i in range(len(dataset))) dan memanggil dataset[i] untuk mengambil label (diasumsikan berbentuk string). Dari semua label dikumpulkan kelas unik, diurutkan, lalu dibuat dua mapping: label_to_idx (label string → integer index) dan idx_to_label (index → label string). Fungsi mengembalikan ketiga objek (label_to_idx, idx_to_label, unique_labels) yang dipakai untuk mengonversi label tekstual menjadi indeks angka saat training/validasi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820d563",
   "metadata": {},
   "source": [
    "## Inisialisasi model MNASNet (create_mnasnet_model)\n",
    "Fungsi ini memuat MNASNet0.5 dengan bobot pretrained (MNASNet0_5_Weights.IMAGENET1K_V1). Ia mencetak informasi model dan classifier awal, lalu—jika freeze_backbone=True—membekukan semua parameter model dengan param.requires_grad = False sehingga hanya layer akhir yang akan dilatih. Layer classifier diganti: diambil in_features dari elemen terakhir model.classifier lalu diganti dengan nn.Sequential(nn.Linear(in_features, num_classes), nn.Softmax(dim=1)). Setelah itu parameter kelas baru di-set requires_grad=True. Fungsi mengembalikan model yang sudah dimodifikasi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e31b0a9",
   "metadata": {},
   "source": [
    "# Model Testing and Prediction Generation\n",
    "\n",
    "This notebook will:\n",
    "1. Load the best trained MNASNet model\n",
    "2. Process test images\n",
    "3. Generate predictions\n",
    "4. Save results to jawaban.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52abff8",
   "metadata": {},
   "source": [
    "## 1. Import Libraries dan Juga Load Modelsnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecf1e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_31484\\2141570886.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_mnasnet_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import mnasnet0_5, MNASNet0_5_Weights\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define class labels\n",
    "idx_to_label = {\n",
    "    0: 'bakso',\n",
    "    1: 'gado_gado',\n",
    "    2: 'nasi_goreng',\n",
    "    3: 'rendang',\n",
    "    4: 'soto_ayam'\n",
    "}\n",
    "\n",
    "# Create model\n",
    "def create_mnasnet_model(num_classes):\n",
    "    weights = MNASNet0_5_Weights.IMAGENET1K_V1\n",
    "    model = mnasnet0_5(weights=weights)\n",
    "    \n",
    "    # Replace the final classification layer\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(in_features, num_classes),\n",
    "        nn.Softmax(dim=1)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = create_mnasnet_model(num_classes=5)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load('best_mnasnet_model.pth'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ed17c",
   "metadata": {},
   "source": [
    "## 2. Load and Process Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea88ceba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 277 test images\n",
      "\n",
      "First few entries from test.csv:\n",
      "   filename  label\n",
      "0  0001.jpg    NaN\n",
      "1  0002.jpg    NaN\n",
      "2  0003.jpg    NaN\n",
      "3  0004.jpg    NaN\n",
      "4  0005.jpg    NaN\n"
     ]
    }
   ],
   "source": [
    "# Read test.csv to get file list\n",
    "test_df = pd.read_csv('test.csv')\n",
    "print(f\"Loaded {len(test_df)} test images\")\n",
    "\n",
    "# Print first few entries to verify\n",
    "print(\"\\nFirst few entries from test.csv:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4d4f1",
   "metadata": {},
   "source": [
    "## 3. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c70b86d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Lenovo\\\\Documents\\\\Semester 7\\\\DeepLearn\\\\test\\\\0001.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m test_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     19\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 20\u001b[0m     pred_label \u001b[38;5;241m=\u001b[39m \u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(pred_label)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36mget_prediction\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_prediction\u001b[39m(image_path):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Load and preprocess image\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     image_tensor \u001b[38;5;241m=\u001b[39m transform(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Documents\\Semester 7\\DeepLearn\\DeepLearn\\lib\\site-packages\\PIL\\Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Lenovo\\\\Documents\\\\Semester 7\\\\DeepLearn\\\\test\\\\0001.jpg'"
     ]
    }
   ],
   "source": [
    "# Function to get prediction\n",
    "def get_prediction(image_path):\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    return idx_to_label[predicted.item()]\n",
    "\n",
    "# Make predictions for all test images\n",
    "predictions = []\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "for idx, row in test_df.iterrows():\n",
    "    image_path = os.path.join('test', row['filename'])\n",
    "    pred_label = get_prediction(image_path)\n",
    "    predictions.append(pred_label)\n",
    "    \n",
    "    if (idx + 1) % 10 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(test_df)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f5f1f",
   "metadata": {},
   "source": [
    "## 4. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f709be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with predictions\n",
    "results_df = pd.DataFrame({\n",
    "    'filename': test_df['filename'],\n",
    "    'label': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('jawaban.csv', index=False)\n",
    "print(\"\\nPredictions saved to jawaban.csv\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(results_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearn (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
